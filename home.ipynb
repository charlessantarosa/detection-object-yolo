{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMIwW+kM0m/Lj2cKT55l0eJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/charlessantarosa/detection-object-yolo/blob/master/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BHJzwe89taS"
      },
      "source": [
        "# Bibliotecas\n",
        "\n",
        "import torch\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications.inception_v3 import preprocess_input\n",
        "from keras.utils.data_utils import GeneratorEnqueuer\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd \n",
        "import numpy as np \n",
        "import math, os\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhJ15SBKBdE7"
      },
      "source": [
        "# Global Vars\n",
        "\n",
        "DATASET_GOOGLE_DRIVER_ID = '1JZIgbTyi6WHAFPfr548-k6YpEg_5MXmb'\n",
        "DATASET_FILE = 'products.zip'\n",
        "DATASET_DIR = 'dataset'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MmZhfE3-UUT"
      },
      "source": [
        "# Yolo\n",
        "\n",
        "!git clone https://github.com/ultralytics/yolov5 || true\n",
        "!ls -la yolov5\n",
        "\n",
        "# Install\n",
        "!pip install -r yolov5/requirements.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcvvma44BTUw",
        "outputId": "b4c48cf6-9f70-4349-b03a-f6bb63ec80ea"
      },
      "source": [
        "# Download do dataset\n",
        "\n",
        "!gdown --id $DATASET_GOOGLE_DRIVER_ID\n",
        "!unzip -o $DATASET_FILE -d $DATASET_DIR > /dev/null\n",
        "\n",
        "print('\\nDataset------------------------------------')\n",
        "!ls -la $DATASET_DIR"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1JZIgbTyi6WHAFPfr548-k6YpEg_5MXmb\n",
            "To: /content/products.zip\n",
            "\r  0% 0.00/452k [00:00<?, ?B/s]\r100% 452k/452k [00:00<00:00, 64.9MB/s]\n",
            "\n",
            "Dataset------------------------------------\n",
            "total 20\n",
            "drwxr-xr-x 5 root root 4096 Nov  2 23:53 .\n",
            "drwxr-xr-x 1 root root 4096 Nov  3 01:21 ..\n",
            "drwxrwxr-x 2 root root 4096 Nov  3 01:21 coca-cola\n",
            "drwxrwxr-x 2 root root 4096 Nov  3 01:21 nescau\n",
            "drwxrwxr-x 2 root root 4096 Nov  3 01:21 pringles\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGhQS1Q1-eWE",
        "outputId": "aeb9c3b5-9f04-470e-8d3e-adc4024456dc"
      },
      "source": [
        "image_path = DATASET_DIR\n",
        "\n",
        "batch_size = 100\n",
        "img_generator = ImageDataGenerator().flow_from_directory(image_path, shuffle=False, batch_size = batch_size)\n",
        "n_rounds = math.ceil(img_generator.samples / img_generator.batch_size)\n",
        "filenames = img_generator.filenames\n",
        "\n",
        "img_generator = GeneratorEnqueuer(img_generator)\n",
        "img_generator.start()\n",
        "img_generator = img_generator.get()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8 images belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7VPyJ3mQqOSQ",
        "outputId": "8a534fdf-db49-4cef-e8a1-8252eb8cbd5d"
      },
      "source": [
        "# https://app.roboflow.com/ds/UiNHC2bX13?key=Avu1fVvHRU\n",
        "!rm -rf roboflow.zip\n",
        "!curl -L \"https://app.roboflow.com/ds/GDPuPJADRI?key=RkIny4fgPG\" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   896  100   896    0     0   1242      0 --:--:-- --:--:-- --:--:--  1240\n",
            "100  242k  100  242k    0     0   268k      0 --:--:-- --:--:-- --:--:--  268k\n",
            "Archive:  roboflow.zip\n",
            "replace README.dataset.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            " extracting: README.dataset.txt      \n",
            " extracting: README.roboflow.txt     \n",
            " extracting: data.yaml               \n",
            " extracting: train/images/agua-coco1_png.rf.5229523bd50333d36cf76b0bd10898d0.jpg  \n",
            " extracting: train/images/coca1_jpg.rf.9351b859950ae57949181ca55bd9ce42.jpg  \n",
            " extracting: train/images/coca2_jpeg.rf.b4d57130474315bd809ce75447229e94.jpg  \n",
            " extracting: train/images/coca3_jpeg.rf.d8f42a33ef422e9485daac866514c12f.jpg  \n",
            " extracting: train/images/coca4_jpeg.rf.d0d6801ddbd33cb50e947a4064c04c02.jpg  \n",
            " extracting: train/images/nescau1_png.rf.eb8a6ad7ad2e3d0348b4cf22ef95c382.jpg  \n",
            " extracting: train/images/pringles1_png.rf.184f603b7933503c78f58720a0dd08ee.jpg  \n",
            " extracting: train/images/pringles2_png.rf.ec125903034845d70b9096b248498a34.jpg  \n",
            " extracting: train/images/pringles3_png.rf.1bb0da4ad8c1328f738a7bdc6e042b5b.jpg  \n",
            " extracting: train/images/pringles4_png.rf.1e72c66e2814f4cb851eeaac80ce2207.jpg  \n",
            " extracting: train/images/todinho1_png.rf.55f8db8a4d5847ad6510907aae9c8443.jpg  \n",
            " extracting: train/images/todinho2_png.rf.ac285316982da6363e8a80aa0eb9e328.jpg  \n",
            " extracting: train/labels/agua-coco1_png.rf.5229523bd50333d36cf76b0bd10898d0.txt  \n",
            " extracting: train/labels/coca1_jpg.rf.9351b859950ae57949181ca55bd9ce42.txt  \n",
            " extracting: train/labels/coca2_jpeg.rf.b4d57130474315bd809ce75447229e94.txt  \n",
            " extracting: train/labels/coca3_jpeg.rf.d8f42a33ef422e9485daac866514c12f.txt  \n",
            " extracting: train/labels/coca4_jpeg.rf.d0d6801ddbd33cb50e947a4064c04c02.txt  \n",
            " extracting: train/labels/nescau1_png.rf.eb8a6ad7ad2e3d0348b4cf22ef95c382.txt  \n",
            " extracting: train/labels/pringles1_png.rf.184f603b7933503c78f58720a0dd08ee.txt  \n",
            " extracting: train/labels/pringles2_png.rf.ec125903034845d70b9096b248498a34.txt  \n",
            " extracting: train/labels/pringles3_png.rf.1bb0da4ad8c1328f738a7bdc6e042b5b.txt  \n",
            " extracting: train/labels/pringles4_png.rf.1e72c66e2814f4cb851eeaac80ce2207.txt  \n",
            " extracting: train/labels/todinho1_png.rf.55f8db8a4d5847ad6510907aae9c8443.txt  \n",
            " extracting: train/labels/todinho2_png.rf.ac285316982da6363e8a80aa0eb9e328.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_MpyPyg0q5HW",
        "outputId": "59a31af7-3808-4ef5-f7eb-a73aa4d5352a"
      },
      "source": [
        "%cat data.yaml"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: ../train/images\n",
            "val: ../valid/images\n",
            "\n",
            "nc: 6\n",
            "names: ['agua-de-coco', 'coca-cola', 'galak-achocolatado', 'nescau-achocolatado', 'pringles', 'toddynho']"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WT5UcLsq4Ugf"
      },
      "source": [
        "# define number of classes based on YAML\n",
        "# data.yaml contains the information about number of classes and their labels required for this project\n",
        "import yaml\n",
        "with open(\"data.yaml\", 'r') as stream:\n",
        "    num_classes = str(yaml.safe_load(stream)['nc'])"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WaEvWoAF4XTL"
      },
      "source": [
        "#customize iPython writefile so we can write variables\n",
        "from IPython.core.magic import register_line_cell_magic\n",
        "\n",
        "@register_line_cell_magic\n",
        "def writetemplate(line, cell):\n",
        "    with open(line, 'w') as f:\n",
        "        f.write(cell.format(**globals()))"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOHDvnpu4Kq-"
      },
      "source": [
        "# Below we are changing the data configuration for right path to the dataset\n",
        "%%writetemplate yolov5/data.yaml\n",
        "\n",
        "train: ./train/images\n",
        "val: ./valid/images\n",
        "\n",
        "nc: 7\n",
        "names: ['fish', 'jellyfish', 'penguin', 'puffin', 'shark', 'starfish', 'stingray']"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEnbY2Gy4lVS"
      },
      "source": [
        "with open(r'data.yaml') as file:\n",
        "    # The FullLoader parameter handles the conversion from YAML\n",
        "    # scalar values to Python the dictionary format\n",
        "    labels_list = yaml.load(file, Loader=yaml.FullLoader)\n",
        "\n",
        "    label_names = labels_list['names']"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvlWG9Y44pTJ",
        "outputId": "10882a6e-25b1-49a4-a196-82e9e11446c6"
      },
      "source": [
        "print(\"Number of Classes are {}, whose labels are {} for this Object Detection project\".format(num_classes,label_names))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Classes are 6, whose labels are ['agua-de-coco', 'coca-cola', 'galak-achocolatado', 'nescau-achocolatado', 'pringles', 'toddynho'] for this Object Detection project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0JoICSAl4sIV",
        "outputId": "f7f22023-31f7-4d03-ccc0-d45ce6bbec14"
      },
      "source": [
        "#this is the model configuration we will use for our tutorial \n",
        "# yolov5s.yaml contains the configuration of neural network required for training.\n",
        "%cat yolov5/models/yolov5s.yaml"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# YOLOv5 ðŸš€ by Ultralytics, GPL-3.0 license\n",
            "\n",
            "# Parameters\n",
            "nc: 80  # number of classes\n",
            "depth_multiple: 0.33  # model depth multiple\n",
            "width_multiple: 0.50  # layer channel multiple\n",
            "anchors:\n",
            "  - [10,13, 16,30, 33,23]  # P3/8\n",
            "  - [30,61, 62,45, 59,119]  # P4/16\n",
            "  - [116,90, 156,198, 373,326]  # P5/32\n",
            "\n",
            "# YOLOv5 v6.0 backbone\n",
            "backbone:\n",
            "  # [from, number, module, args]\n",
            "  [[-1, 1, Conv, [64, 6, 2, 2]],  # 0-P1/2\n",
            "   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4\n",
            "   [-1, 3, C3, [128]],\n",
            "   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8\n",
            "   [-1, 6, C3, [256]],\n",
            "   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16\n",
            "   [-1, 9, C3, [512]],\n",
            "   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32\n",
            "   [-1, 3, C3, [1024]],\n",
            "   [-1, 1, SPPF, [1024, 5]],  # 9\n",
            "  ]\n",
            "\n",
            "# YOLOv5 v6.0 head\n",
            "head:\n",
            "  [[-1, 1, Conv, [512, 1, 1]],\n",
            "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
            "   [[-1, 6], 1, Concat, [1]],  # cat backbone P4\n",
            "   [-1, 3, C3, [512, False]],  # 13\n",
            "\n",
            "   [-1, 1, Conv, [256, 1, 1]],\n",
            "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
            "   [[-1, 4], 1, Concat, [1]],  # cat backbone P3\n",
            "   [-1, 3, C3, [256, False]],  # 17 (P3/8-small)\n",
            "\n",
            "   [-1, 1, Conv, [256, 3, 2]],\n",
            "   [[-1, 14], 1, Concat, [1]],  # cat head P4\n",
            "   [-1, 3, C3, [512, False]],  # 20 (P4/16-medium)\n",
            "\n",
            "   [-1, 1, Conv, [512, 3, 2]],\n",
            "   [[-1, 10], 1, Concat, [1]],  # cat head P5\n",
            "   [-1, 3, C3, [1024, False]],  # 23 (P5/32-large)\n",
            "\n",
            "   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)\n",
            "  ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJwxGDvS4yqd"
      },
      "source": [
        "# Below we are changing the configuration so that it becomes compatible to number of classes required in this project\n",
        "%%writetemplate yolov5/models/custom_yolov5s.yaml\n",
        "\n",
        "# parameters\n",
        "nc: {num_classes}  # number of classes  # CHANGED HERE\n",
        "depth_multiple: 0.33  # model depth multiple\n",
        "width_multiple: 0.50  # layer channel multiple\n",
        "\n",
        "# anchors\n",
        "anchors:\n",
        "  - [10,13, 16,30, 33,23]  # P3/8\n",
        "  - [30,61, 62,45, 59,119]  # P4/16\n",
        "  - [116,90, 156,198, 373,326]  # P5/32\n",
        "\n",
        "# YOLOv5 backbone\n",
        "backbone:\n",
        "  # [from, number, module, args]\n",
        "  [[-1, 1, Focus, [64, 3]],  # 0-P1/2\n",
        "   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4\n",
        "   [-1, 3, BottleneckCSP, [128]],\n",
        "   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8\n",
        "   [-1, 9, BottleneckCSP, [256]],\n",
        "   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16\n",
        "   [-1, 9, BottleneckCSP, [512]],\n",
        "   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32\n",
        "   [-1, 1, SPP, [1024, [5, 9, 13]]],\n",
        "   [-1, 3, BottleneckCSP, [1024, False]],  # 9\n",
        "  ]\n",
        "\n",
        "# YOLOv5 head\n",
        "head:\n",
        "  [[-1, 1, Conv, [512, 1, 1]],\n",
        "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
        "   [[-1, 6], 1, Concat, [1]],  # cat backbone P4\n",
        "   [-1, 3, BottleneckCSP, [512, False]],  # 13\n",
        "\n",
        "   [-1, 1, Conv, [256, 1, 1]],\n",
        "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
        "   [[-1, 4], 1, Concat, [1]],  # cat backbone P3\n",
        "   [-1, 3, BottleneckCSP, [256, False]],  # 17 (P3/8-small)\n",
        "\n",
        "   [-1, 1, Conv, [256, 3, 2]],\n",
        "   [[-1, 14], 1, Concat, [1]],  # cat head P4\n",
        "   [-1, 3, BottleneckCSP, [512, False]],  # 20 (P4/16-medium)\n",
        "\n",
        "   [-1, 1, Conv, [512, 3, 2]],\n",
        "   [[-1, 10], 1, Concat, [1]],  # cat head P5\n",
        "   [-1, 3, BottleneckCSP, [1024, False]],  # 23 (P5/32-large)\n",
        "\n",
        "   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)\n",
        "  ]"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tz_VKr2j46j6"
      },
      "source": [
        "import os\n",
        "os.chdir('yolov5')"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-9cOZf84_Ne",
        "outputId": "e23aae53-5277-4576-b0f2-600889a79d60"
      },
      "source": [
        "%%time\n",
        "!python train.py --img 416 --batch 80 --epochs 100 --data './data.yaml' --cfg ./models/custom_yolov5s.yaml --weights ''"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=, cfg=./models/custom_yolov5s.yaml, data=./data.yaml, hyp=data/hyps/hyp.scratch.yaml, epochs=100, batch_size=80, imgsz=416, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, adam=False, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, patience=100, freeze=0, save_period=-1, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 âœ…\n",
            "YOLOv5 ðŸš€ v6.0-45-g042f02f torch 1.9.0+cu111 CUDA:0 (Tesla P100-PCIE-16GB, 16280.875MB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 ðŸš€ runs (RECOMMENDED)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "\n",
            "WARNING: Dataset not found, nonexistent paths: ['/content/yolov5/valid/images']\n",
            "Traceback (most recent call last):\n",
            "  File \"train.py\", line 625, in <module>\n",
            "    main(opt)\n",
            "  File \"train.py\", line 522, in main\n",
            "    train(opt.hyp, opt, device, callbacks)\n",
            "  File \"train.py\", line 103, in train\n",
            "    data_dict = data_dict or check_dataset(data)  # check if None\n",
            "  File \"/content/yolov5/utils/general.py\", line 401, in check_dataset\n",
            "    raise Exception('Dataset not found.')\n",
            "Exception: Dataset not found.\n",
            "CPU times: user 31.8 ms, sys: 24.2 ms, total: 56 ms\n",
            "Wall time: 4.15 s\n"
          ]
        }
      ]
    }
  ]
}
